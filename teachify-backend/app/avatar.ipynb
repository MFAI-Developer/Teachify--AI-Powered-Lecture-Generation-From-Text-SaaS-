{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wX6FXlEkrS4Q",
    "outputId": "8c4cfda1-35d3-414c-dc0b-6295f88cef3d",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "!pip install azure-identity\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,  # set to logging.DEBUG for verbose output\n",
    "          format=\"[%(asctime)s] %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "  # The endpoint (and key) could be gotten from the Keys and Endpoint page in the Speech service resource.\n",
    "  # The endpoint would be like: https://<region>.api.cognitive.microsoft.com or https://<custom_domain>.cognitiveservices.azure.com\n",
    "  # If you want to use passwordless authentication, custom domain is required.\n",
    "SPEECH_ENDPOINT = os.getenv('SPEECH_ENDPOINT',\"https://eastus.api.cognitive.microsoft.com\")\n",
    "  # We recommend to use passwordless authentication with Azure Identity here; meanwhile, you can also use a subscription key instead\n",
    "PASSWORDLESS_AUTHENTICATION = False\n",
    "API_VERSION = \"2024-04-15-preview\"\n",
    "\n",
    "\n",
    "def _create_job_id():\n",
    "      # the job ID must be unique in current speech resource\n",
    "      # you can use a GUID or a self-increasing number\n",
    "      return uuid.uuid4()\n",
    "\n",
    "\n",
    "def _authenticate():\n",
    "      if PASSWORDLESS_AUTHENTICATION:\n",
    "          # Refer to https://learn.microsoft.com/python/api/overview/azure/identity-readme?view=azure-python#defaultazurecredential\n",
    "          # for more information about Azure Identity\n",
    "          # For example, your app can authenticate using your Azure CLI sign-in credentials with when developing locally.\n",
    "          # Your app can then use a managed identity once it has been deployed to Azure. No code changes are required for this transition.\n",
    "\n",
    "          # When developing locally, make sure that the user account that is accessing batch avatar synthesis has the right permission.\n",
    "          # You'll need Cognitive Services User or Cognitive Services Speech User role to submit batch avatar synthesis jobs.\n",
    "          credential = DefaultAzureCredential()\n",
    "          token = credential.get_token('https://cognitiveservices.azure.com/.default')\n",
    "          return {'Authorization': f'Bearer {token.token}'}\n",
    "      else:\n",
    "          SUBSCRIPTION_KEY = os.getenv(\"SUBSCRIPTION_KEY\", '66ErdoDFrV35hVw3LVaKSzKsxOxkeQT4KFKBCbm1mwKOBZMIm2uhJQQJ99BKACYeBjFXJ3w3AAAYACOGN5qt')\n",
    "          return {'Ocp-Apim-Subscription-Key': SUBSCRIPTION_KEY}\n",
    "\n",
    "\n",
    "def submit_synthesis(job_id: str):\n",
    "      url = f'{SPEECH_ENDPOINT}/avatar/batchsyntheses/{job_id}?api-version={API_VERSION}'\n",
    "      header = {\n",
    "          'Content-Type': 'application/json'\n",
    "      }\n",
    "      header.update(_authenticate())\n",
    "      isCustomized = False\n",
    "\n",
    "      payload = {\n",
    "          'synthesisConfig': {\n",
    "              \"voice\": 'en-US-AvaMultilingualNeural',\n",
    "          },\n",
    "          # Replace with your custom voice name and deployment ID if you want to use custom voice.\n",
    "          # Multiple voices are supported, the mixture of custom voices and platform voices is allowed.\n",
    "          # Invalid voice name or deployment ID will be rejected.\n",
    "          'customVoices': {\n",
    "              # \"YOUR_CUSTOM_VOICE_NAME\": \"YOUR_CUSTOM_VOICE_ID\"\n",
    "          },\n",
    "          \"inputKind\": \"plainText\",\n",
    "          \"inputs\": [\n",
    "              {\n",
    "                  \"content\": \"my name is usama shakeel i recently passed my graduation at bs AI from comsats university islamabad attock campus , As an AI Engineer specializing in ML,with expertise in Deep Learning, NLP, CV, Generative AI and Agents.Expertise in LLMs LLaMA, Mistral, GPT, Claude, Gemini, Qwen-VL, Gemma and Ollama, llama.cpp (for local, private use) for developing advanced AI agents. Proficient with Groq, OpenAI, Together, (RAG), fine-tuning, chatbots and prompt engineering to develop intelligent, context-aware systems.Experienced in agent-based automation using frameworks like LangChain,LlamaIndex, LangGraph,CrewAI and Livekit. Proficient in AIaaS, Saas, Full-Stack & Products deploymet with scalable AI solutions\",\n",
    "              },\n",
    "          ],\n",
    "          \"avatarConfig\":\n",
    "           {\n",
    "              \"customized\": isCustomized, # set to True if you want to use customized avatar\n",
    "              \"talkingAvatarCharacter\": 'Max-business',  # talking avatar character\n",
    "              \"videoFormat\": \"mp4\",  # mp4 or webm, webm is required for transparent background\n",
    "              \"videoCodec\": \"h264\",  # hevc, h264 or vp9, vp9 is required for transparent background; default is hevc\n",
    "              \"subtitleType\": \"soft_embedded\",\n",
    "              \"backgroundColor\": \"#FFFFFFFF\", # background color in RGBA format, default is white; can be set to 'transparent' for transparent background\n",
    "              # \"backgroundImage\": \"https://samples-files.com/samples/Images/jpg/1920-1080-sample.jpg\", # background image URL, only support https, either backgroundImage or backgroundColor can be set\n",
    "          }\n",
    "          if isCustomized\n",
    "          else\n",
    "          {\n",
    "            \"customized\": isCustomized, # set to True if you want to use customized avatar\n",
    "            \"talkingAvatarCharacter\": 'Max',  # talking avatar character\n",
    "            \"talkingAvatarStyle\": 'business',  # talking avatar style, required for prebuilt avatar, optional for custom avatar\n",
    "            \"videoFormat\": \"mp4\",  # mp4 or webm, webm is required for transparent background\n",
    "            \"videoCodec\": \"h264\",  # hevc, h264 or vp9, vp9 is required for transparent background; default is hevc\n",
    "            \"subtitleType\": \"soft_embedded\",\n",
    "            \"backgroundColor\": \"#FFFFFFFF\", # background color in RGBA format, default is white; can be set to 'transparent' for transparent background\n",
    "            # \"backgroundImage\": \"https://samples-files.com/samples/Images/jpg/1920-1080-sample.jpg\", # background image URL, only support https, either backgroundImage or backgroundColor can be set\n",
    "        }\n",
    "      }\n",
    "\n",
    "      response = requests.put(url, json.dumps(payload), headers=header)\n",
    "      if response.status_code < 400:\n",
    "          logger.info('Batch avatar synthesis job submitted successfully')\n",
    "          logger.info(f'Job ID: {response.json()[\"id\"]}')\n",
    "          return True\n",
    "      else:\n",
    "          logger.error(f'Failed to submit batch avatar synthesis job: [{response.status_code}], {response.text}')\n",
    "\n",
    "\n",
    "def get_synthesis(job_id):\n",
    "      url = f'{SPEECH_ENDPOINT}/avatar/batchsyntheses/{job_id}?api-version={API_VERSION}'\n",
    "      header = _authenticate()\n",
    "\n",
    "      response = requests.get(url, headers=header)\n",
    "      if response.status_code < 400:\n",
    "          logger.debug('Get batch synthesis job successfully')\n",
    "          logger.debug(response.json())\n",
    "          if response.json()['status'] == 'Succeeded':\n",
    "              logger.info(f'Batch synthesis job succeeded, download URL: {response.json()[\"outputs\"][\"result\"]}')\n",
    "          return response.json()['status']\n",
    "      else:\n",
    "          logger.error(f'Failed to get batch synthesis job: {response.text}')\n",
    "\n",
    "\n",
    "def list_synthesis_jobs(skip: int = 0, max_page_size: int = 100):\n",
    "      \"\"\"List all batch synthesis jobs in the subscription\"\"\"\n",
    "      url = f'{SPEECH_ENDPOINT}/avatar/batchsyntheses?api-version={API_VERSION}&skip={skip}&maxpagesize={max_page_size}'\n",
    "      header = _authenticate()\n",
    "\n",
    "      response = requests.get(url, headers=header)\n",
    "      if response.status_code < 400:\n",
    "          logger.info(f'List batch synthesis jobs successfully, got {len(response.json()[\"values\"])} jobs')\n",
    "          logger.info(response.json())\n",
    "      else:\n",
    "          logger.error(f'Failed to list batch synthesis jobs: {response.text}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_id = _create_job_id()\n",
    "    print(\"Generated job ID:\", job_id)  # ðŸ‘ˆ add this to confirm the code runs\n",
    "\n",
    "    result = submit_synthesis(job_id)\n",
    "    print(\"Submit result:\", result)\n",
    "\n",
    "    if result:\n",
    "        while True:\n",
    "            status = get_synthesis(job_id)\n",
    "            print(\"Job status:\", status)\n",
    "            if status in [\"Succeeded\", \"Failed\"]:\n",
    "                break\n",
    "            time.sleep(5)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
